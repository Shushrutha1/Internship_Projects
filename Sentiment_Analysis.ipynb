{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34671a4b-77c2-4aad-8fcc-7185a8623f55",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mre\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnltk\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mplt\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sentiment Analysis of Restaurant Reviews\n",
    "----------------------------------------\n",
    "This project applies Natural Language Processing (NLP) to classify restaurant reviews\n",
    "as positive or negative using a Naive Bayes classifier.\n",
    "\n",
    "Steps:\n",
    "1. Data loading & exploration\n",
    "2. Text preprocessing (cleaning, tokenization, stopword removal, stemming)\n",
    "3. Feature extraction using Bag of Words\n",
    "4. Model training & evaluation\n",
    "5. Hyperparameter tuning (alpha for MultinomialNB)\n",
    "6. Custom review prediction\n",
    "\"\"\"\n",
    "\n",
    "# ===============================\n",
    "# 1. Import Required Libraries\n",
    "# ===============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Suppress NLTK download messages\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='nltk')\n",
    "\n",
    "# Download stopwords quietly\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 2. Load Dataset\n",
    "# ===============================\n",
    "data = pd.read_csv('Restaurant_Reviews.tsv', delimiter='\\t', quoting=3)\n",
    "print(f\"Dataset Shape: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns)}\\n\")\n",
    "print(data.head(), \"\\n\")\n",
    "data.info()\n",
    "\n",
    "# ===============================\n",
    "# 3. Text Preprocessing\n",
    "# ===============================\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "corpus = []\n",
    "\n",
    "for review in data['Review']:\n",
    "    # Keep only letters\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    words = review.split()\n",
    "\n",
    "    # Remove stopwords and apply stemming\n",
    "    words = [ps.stem(word) for word in words if word not in stop_words]\n",
    "\n",
    "    corpus.append(' '.join(words))\n",
    "\n",
    "# ===============================\n",
    "# 4. Feature Extraction\n",
    "# ===============================\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "# ===============================\n",
    "# 5. Train-Test Split\n",
    "# ===============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# 6. Model Training (Naive Bayes)\n",
    "# ===============================\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# ===============================\n",
    "# 7. Model Evaluation\n",
    "# ===============================\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"\\n--------- MODEL PERFORMANCE ---------\")\n",
    "print(f\"Accuracy : {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall   : {recall*100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# ===============================\n",
    "# 8. Hyperparameter Tuning (Alpha)\n",
    "# ===============================\n",
    "best_accuracy = 0.0\n",
    "best_alpha = 0.0\n",
    "print(\"\\n------ Alpha Tuning Results ------\")\n",
    "for alpha in np.arange(0.1, 1.1, 0.1):\n",
    "    temp_clf = MultinomialNB(alpha=alpha)\n",
    "    temp_clf.fit(X_train, y_train)\n",
    "    temp_pred = temp_clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, temp_pred)\n",
    "    print(f\"Alpha={alpha:.1f} => Accuracy: {score*100:.2f}%\")\n",
    "    if score > best_accuracy:\n",
    "        best_accuracy = score\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"\\nBest Accuracy: {best_accuracy*100:.2f}% with Alpha={best_alpha:.1f}\")\n",
    "\n",
    "# Retrain with best alpha\n",
    "classifier = MultinomialNB(alpha=best_alpha)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# ===============================\n",
    "# 9. Custom Review Prediction Function\n",
    "# ===============================\n",
    "def predict_sentiment(sample_review: str) -> str:\n",
    "    \"\"\"\n",
    "    Predicts sentiment (Positive/Negative) for a given review string.\n",
    "    \"\"\"\n",
    "    sample_review = re.sub('[^a-zA-Z]', ' ', sample_review)\n",
    "    sample_review = sample_review.lower()\n",
    "    words = sample_review.split()\n",
    "    words = [ps.stem(word) for word in words if word not in stop_words]\n",
    "    final_review = ' '.join(words)\n",
    "    vector = cv.transform([final_review]).toarray()\n",
    "    prediction = classifier.predict(vector)[0]\n",
    "    return \"Positive Review\" if prediction == 1 else \"Negative Review\"\n",
    "\n",
    "# ===============================\n",
    "# 10. Sample Predictions\n",
    "# ===============================\n",
    "sample_reviews = [\n",
    "    \"The food is really bad.\",\n",
    "    \"Food was pretty bad and the service was very slow.\",\n",
    "    \"The food was absolutely wonderful, from preparation to presentation, very pleasing.\",\n",
    "    \"food averag\"\n",
    "]\n",
    "\n",
    "print(\"\\n------ SAMPLE PREDICTIONS ------\")\n",
    "for review in sample_reviews:\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Sentiment: {predict_sentiment(review)}\\n\")\n",
    "\n",
    "# ===============================\n",
    "# 11. Interactive User Input\n",
    "# ===============================\n",
    "while True:\n",
    "    user_input = input(\"Enter a review (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Exiting sentiment prediction. Goodbye!\")\n",
    "        break\n",
    "    print(\"Predicted Sentiment:\", predict_sentiment(user_input), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
